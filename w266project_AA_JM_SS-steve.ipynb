{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIAR DETECTION GROUP PROJECT\n",
    "\n",
    "Run the cell below to import packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import json, os, re, shutil, sys, time\n",
    "from importlib import reload\n",
    "import collections, itertools\n",
    "import unittest\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.utils import shuffle\n",
    "# NLTK for NLP utils and corpora\n",
    "import nltk\n",
    "\n",
    "# NumPy and TensorFlow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# Helper libraries\n",
    "from w266_common import utils, vocabulary, tf_embed_viz\n",
    "#from ark-tweet-nlp-0.3.2 import \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "Loading the \"Fake News\" dataset from the Information security and object technology (ISOT) Research lab at the University of Victoria School of Engineering.\n",
    "\n",
    "The ISOT Fake News Dataset is a compilation of several thousands fake news and truthful articles, obtained from different legitimate news sites and sites flagged as unreliable by politifact.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>44898</td>\n",
       "      <td>44898</td>\n",
       "      <td>44898</td>\n",
       "      <td>44898</td>\n",
       "      <td>44898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>38729</td>\n",
       "      <td>38646</td>\n",
       "      <td>8</td>\n",
       "      <td>2397</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Factbox: Trump fills top jobs for his administ...</td>\n",
       "      <td></td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 20, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>14</td>\n",
       "      <td>627</td>\n",
       "      <td>11272</td>\n",
       "      <td>182</td>\n",
       "      <td>23481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title   text  \\\n",
       "count                                               44898  44898   \n",
       "unique                                              38729  38646   \n",
       "top     Factbox: Trump fills top jobs for his administ...          \n",
       "freq                                                   14    627   \n",
       "\n",
       "             subject                date target  \n",
       "count          44898               44898  44898  \n",
       "unique             8                2397      2  \n",
       "top     politicsNews  December 20, 2017       0  \n",
       "freq           11272                 182  23481  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define each downloaded file\n",
    "FAKE_FILENAME = 'Fake.csv'\n",
    "TRUE_FILENAME = 'True.csv'\n",
    "\n",
    "# define the downloaded file path \n",
    "DATAPATH = './datasets/ISOT_FakeNews/'\n",
    "\n",
    "def get_data(filename):\n",
    "    '''Read CSV file into a pandas dataframe'''\n",
    "      \n",
    "    filepath = DATAPATH + filename\n",
    "    return pd.read_csv(filepath, header=0, sep=',', quotechar='\"')\n",
    "\n",
    "\n",
    "fake_data = get_data(FAKE_FILENAME)\n",
    "true_data = get_data(TRUE_FILENAME)\n",
    "\n",
    "\n",
    "\n",
    "# add a label column to the data with the target values\n",
    "fake_data.loc[:,'target'] = '0'\n",
    "true_data['target'] = '1'\n",
    "\n",
    "#append the datasets and shuffle them\n",
    "all_data = true_data.append(fake_data, ignore_index=True)\n",
    "all_data = all_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "all_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trump to nominate Raytheon lobbyist for Army s...</td>\n",
       "      <td>WASHINGTON (Reuters) - U.S. President Donald T...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>July 19, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thailand approves $2.2 billion in help for ric...</td>\n",
       "      <td>BANGKOK (Reuters) - Thailand s government on F...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>September 1, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>White House confident it will 'prevail' on tra...</td>\n",
       "      <td>ON BOARD AIR FORCE ONE (Reuters) - The White H...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>February 6, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Republican establishment bails on Alabama cand...</td>\n",
       "      <td>(Reuters) - The national campaign wing for U.S...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>November 10, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump’s Administration Was Just Caught Up In ...</td>\n",
       "      <td>While it can be said that no one is immune fro...</td>\n",
       "      <td>News</td>\n",
       "      <td>April 5, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A young Chinese rebel feels the pull of family...</td>\n",
       "      <td>CHENGDU, China (Reuters) - Her stepfather was ...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>October 17, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Democratic National Committee apologizes to Sa...</td>\n",
       "      <td>(Reuters) - The Democratic National Committee ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>July 25, 2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Children Of Christian Fundamentalists Are...</td>\n",
       "      <td>Christian Fundamentalism is putting American c...</td>\n",
       "      <td>News</td>\n",
       "      <td>March 9, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>U.S. urges Venezuela to release U.S. citizen h...</td>\n",
       "      <td>WASHINGTON (Reuters) - The U.S. State Departme...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>November 30, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Factbox: Trump on Twitter (Aug 1) - Stock mark...</td>\n",
       "      <td>The following statements were posted to the ve...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>August 1, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>IDENTITY OF HILLARY’S MYSTERY “HANDLER” Is Fin...</td>\n",
       "      <td>About a month ago, people started noticing a l...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>Sep 9, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>OBAMA’S OPEN BORDERS Crisis Just Got Real…WHO ...</td>\n",
       "      <td>We recently reported about the deadly Zika vir...</td>\n",
       "      <td>politics</td>\n",
       "      <td>Jan 29, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Clinton far ahead in Electoral College race: R...</td>\n",
       "      <td>NEW YORK (Reuters) - Democratic candidate Hill...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>October 22, 2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>WHOA! NEW EMAILS SHOW COMEY FBI LIED About Mee...</td>\n",
       "      <td>A new email dump from the FBI via a FOIA reque...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>Aug 4, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>California voters embrace recreational marijuana</td>\n",
       "      <td>SACRAMENTO, Calif./LOS ANGELES (Reuters) - A b...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>November 8, 2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0   Trump to nominate Raytheon lobbyist for Army s...   \n",
       "1   Thailand approves $2.2 billion in help for ric...   \n",
       "2   White House confident it will 'prevail' on tra...   \n",
       "3   Republican establishment bails on Alabama cand...   \n",
       "4    Trump’s Administration Was Just Caught Up In ...   \n",
       "5   A young Chinese rebel feels the pull of family...   \n",
       "6   Democratic National Committee apologizes to Sa...   \n",
       "7    The Children Of Christian Fundamentalists Are...   \n",
       "8   U.S. urges Venezuela to release U.S. citizen h...   \n",
       "9   Factbox: Trump on Twitter (Aug 1) - Stock mark...   \n",
       "10  IDENTITY OF HILLARY’S MYSTERY “HANDLER” Is Fin...   \n",
       "11  OBAMA’S OPEN BORDERS Crisis Just Got Real…WHO ...   \n",
       "12  Clinton far ahead in Electoral College race: R...   \n",
       "13  WHOA! NEW EMAILS SHOW COMEY FBI LIED About Mee...   \n",
       "14   California voters embrace recreational marijuana   \n",
       "\n",
       "                                                 text       subject  \\\n",
       "0   WASHINGTON (Reuters) - U.S. President Donald T...  politicsNews   \n",
       "1   BANGKOK (Reuters) - Thailand s government on F...     worldnews   \n",
       "2   ON BOARD AIR FORCE ONE (Reuters) - The White H...  politicsNews   \n",
       "3   (Reuters) - The national campaign wing for U.S...  politicsNews   \n",
       "4   While it can be said that no one is immune fro...          News   \n",
       "5   CHENGDU, China (Reuters) - Her stepfather was ...     worldnews   \n",
       "6   (Reuters) - The Democratic National Committee ...  politicsNews   \n",
       "7   Christian Fundamentalism is putting American c...          News   \n",
       "8   WASHINGTON (Reuters) - The U.S. State Departme...     worldnews   \n",
       "9   The following statements were posted to the ve...  politicsNews   \n",
       "10  About a month ago, people started noticing a l...     left-news   \n",
       "11  We recently reported about the deadly Zika vir...      politics   \n",
       "12  NEW YORK (Reuters) - Democratic candidate Hill...  politicsNews   \n",
       "13  A new email dump from the FBI via a FOIA reque...     left-news   \n",
       "14  SACRAMENTO, Calif./LOS ANGELES (Reuters) - A b...  politicsNews   \n",
       "\n",
       "                  date target  \n",
       "0       July 19, 2017       1  \n",
       "1   September 1, 2017       1  \n",
       "2    February 6, 2017       1  \n",
       "3   November 10, 2017       1  \n",
       "4        April 5, 2017      0  \n",
       "5    October 17, 2017       1  \n",
       "6       July 25, 2016       1  \n",
       "7        March 9, 2016      0  \n",
       "8   November 30, 2017       1  \n",
       "9      August 1, 2017       1  \n",
       "10         Sep 9, 2016      0  \n",
       "11        Jan 29, 2016      0  \n",
       "12   October 22, 2016       1  \n",
       "13         Aug 4, 2017      0  \n",
       "14   November 8, 2016       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fake_data.head(15)\n",
    "#true_data.head(16)\n",
    "all_data.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Donald Trump Sends Out Embarrassing New Year’s Eve Message; This is Disturbing\n",
      "\n",
      " Donald Trump just couldn t wish all Americans a Happy New Year and leave it at that. Instead, he had to give a shout out to his enemies, haters and  the very dishonest fake news media.  The former reality show star had just one job to do and he couldn t do it. As our Country rapidly grows stronger and smarter, I want to wish all of my friends, supporters, enemies, haters, and even the very dishonest Fake News Media, a Happy and Healthy New Year,  President Angry Pants tweeted.  2018 will be a great year for America! As our Country rapidly grows stronger and smarter, I want to wish all of my friends, supporters, enemies, haters, and even the very dishonest Fake News Media, a Happy and Healthy New Year. 2018 will be a great year for America!  Donald J. Trump (@realDonaldTrump) December 31, 2017Trump s tweet went down about as welll as you d expect.What kind of president sends a New Year s greeting like this despicable, petty, infantile gibberish? Only Trump! His lack of decency won t even allow him to rise above the gutter long enough to wish the American citizens a happy new year!  Bishop Talbert Swan (@TalbertSwan) December 31, 2017no one likes you  Calvin (@calvinstowell) December 31, 2017Your impeachment would make 2018 a great year for America, but I ll also accept regaining control of Congress.  Miranda Yaver (@mirandayaver) December 31, 2017Do you hear yourself talk? When you have to include that many people that hate you you have to wonder? Why do the they all hate me?  Alan Sandoval (@AlanSandoval13) December 31, 2017Who uses the word Haters in a New Years wish??  Marlene (@marlene399) December 31, 2017You can t just say happy new year?  Koren pollitt (@Korencarpenter) December 31, 2017Here s Trump s New Year s Eve tweet from 2016.Happy New Year to all, including to my many enemies and those who have fought me and lost so badly they just don t know what to do. Love!  Donald J. Trump (@realDonaldTrump) December 31, 2016This is nothing new for Trump. He s been doing this for years.Trump has directed messages to his  enemies  and  haters  for New Year s, Easter, Thanksgiving, and the anniversary of 9/11. pic.twitter.com/4FPAe2KypA  Daniel Dale (@ddale8) December 31, 2017Trump s holiday tweets are clearly not presidential.How long did he work at Hallmark before becoming President?  Steven Goodine (@SGoodine) December 31, 2017He s always been like this . . . the only difference is that in the last few years, his filter has been breaking down.  Roy Schulze (@thbthttt) December 31, 2017Who, apart from a teenager uses the term haters?  Wendy (@WendyWhistles) December 31, 2017he s a fucking 5 year old  Who Knows (@rainyday80) December 31, 2017So, to all the people who voted for this a hole thinking he would change once he got into power, you were wrong! 70-year-old men don t change and now he s a year older.Photo by Andrew Burton/Getty Images.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(fake_data.title[0])\n",
    "print('\\n', fake_data.text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "Check for NA values.\n",
    "\n",
    "May not want the dataset to contain the 'subject' since all the true news data comes from \"Reuters\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title      0\n",
       "text       0\n",
       "subject    0\n",
       "date       0\n",
       "target     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44898 entries, 0 to 44897\n",
      "Data columns (total 5 columns):\n",
      "title      44898 non-null object\n",
      "text       44898 non-null object\n",
      "subject    44898 non-null object\n",
      "date       44898 non-null object\n",
      "target     44898 non-null object\n",
      "dtypes: object(5)\n",
      "memory usage: 151.9 MB\n"
     ]
    }
   ],
   "source": [
    "all_data.info(memory_usage='deep', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize and Canonicalize Text\n",
    "\n",
    "Need to work on Tokenize and Canonicalizing text. Words like \"Obama's\" need to be corrected. Do we need to mark of sentences within a text? Might want to use some regex code from camron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my',\n",
       " 'name',\n",
       " 'is',\n",
       " 'abhishek',\n",
       " '.',\n",
       " 'i',\n",
       " 'have',\n",
       " 'no',\n",
       " 'clue',\n",
       " '.',\n",
       " 'learning',\n",
       " 'the',\n",
       " 'back',\n",
       " '-',\n",
       " 'portion',\n",
       " 'that',\n",
       " 'i',\n",
       " 'never',\n",
       " 'cared',\n",
       " 'for',\n",
       " '.',\n",
       " 'obama',\n",
       " \"'\",\n",
       " 's',\n",
       " 'nephew',\n",
       " '.',\n",
       " '<user>']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Source:  https://gist.github.com/tokestermw/cb87a97113da12acb388\n",
    "\"\"\"\n",
    "\n",
    "FLAGS = re.MULTILINE | re.DOTALL\n",
    "\n",
    "def hashtag(text):\n",
    "    text = text.group()\n",
    "    hashtag_body = text[1:]\n",
    "    if hashtag_body.isupper():\n",
    "        result = \" {} \".format(hashtag_body.lower())\n",
    "    else:\n",
    "        result = \" \".join([\"<hashtag>\"] + re.split(r\"(?=[A-Z])\", hashtag_body, flags=FLAGS))\n",
    "    return result\n",
    "\n",
    "def allcaps(text):\n",
    "    text = text.group()\n",
    "    return text.lower() + \" <allcaps>\"\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    # Different regex parts for smiley faces\n",
    "    eyes = r\"[8:=;]\"\n",
    "    nose = r\"['`\\-]?\"\n",
    "\n",
    "    # function so code less repetitive\n",
    "    def re_sub(pattern, repl):\n",
    "        return re.sub(pattern, repl, text, flags=FLAGS)\n",
    "\n",
    "    text = re_sub(r\"https?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*\", \"<url>\")\n",
    "    text = re_sub(r\"@\\w+\", \"<user>\")\n",
    "    text = re_sub(r\"{}{}[)dD]+|[)dD]+{}{}\".format(eyes, nose, nose, eyes), \"<smile>\")\n",
    "    text = re_sub(r\"{}{}p+\".format(eyes, nose), \"<lolface>\")\n",
    "    text = re_sub(r\"{}{}\\(+|\\)+{}{}\".format(eyes, nose, nose, eyes), \"<sadface>\")\n",
    "    text = re_sub(r\"{}{}[\\/|l*]\".format(eyes, nose), \"<neutralface>\")\n",
    "    text = re_sub(r\"/\",\" / \")\n",
    "    text = re_sub(r\"<3\",\"<heart>\")\n",
    "    text = re_sub(r\"[-+]?[.\\d]*[\\d]+[:,.\\d]*\", \"<number>\")\n",
    "   # text = re_sub(r\"#\\S+\", hashtag)\n",
    "    text = re_sub(r\"([!?.]){2,}\", r\"\\1 <repeat>\")\n",
    "    text = re_sub(r\"\\b(\\S*?)(.)\\2{2,}\\b\", r\"\\1\\2 <elong>\")\n",
    "    text = re_sub(r\"([A-Z]){2,}\", allcaps)\n",
    "\n",
    "       \n",
    "    output = text.lower().split()\n",
    "    output = list(itertools.chain(*[re.split(r'([^\\w<>])', x) for x in output]))  #Splits punctuation, keeping < and >\n",
    "    return [item for item in output if item != '']  #Removes blank strings from list\n",
    "\n",
    "teststring = \"My name is Abhishek. I have no clue. Learning the back-portion that I never cared for. Obama's nephew. @random\"\n",
    "tokenize(teststring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My</td>\n",
       "      <td>D</td>\n",
       "      <td>0.9984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>name</td>\n",
       "      <td>N</td>\n",
       "      <td>0.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is</td>\n",
       "      <td>V</td>\n",
       "      <td>0.9973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abhishek</td>\n",
       "      <td>^</td>\n",
       "      <td>0.9628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.</td>\n",
       "      <td>,</td>\n",
       "      <td>0.9975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I</td>\n",
       "      <td>O</td>\n",
       "      <td>0.9980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>have</td>\n",
       "      <td>V</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>no</td>\n",
       "      <td>D</td>\n",
       "      <td>0.9911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>clue</td>\n",
       "      <td>N</td>\n",
       "      <td>0.9998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>.</td>\n",
       "      <td>,</td>\n",
       "      <td>0.9985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Learning</td>\n",
       "      <td>V</td>\n",
       "      <td>0.9957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>the</td>\n",
       "      <td>D</td>\n",
       "      <td>0.9960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>back-portion</td>\n",
       "      <td>N</td>\n",
       "      <td>0.8394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>that</td>\n",
       "      <td>P</td>\n",
       "      <td>0.9530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I</td>\n",
       "      <td>O</td>\n",
       "      <td>0.9989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>never</td>\n",
       "      <td>R</td>\n",
       "      <td>0.9922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cared</td>\n",
       "      <td>V</td>\n",
       "      <td>0.9976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>for</td>\n",
       "      <td>P</td>\n",
       "      <td>0.9806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>.</td>\n",
       "      <td>,</td>\n",
       "      <td>0.9916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Obama's</td>\n",
       "      <td>Z</td>\n",
       "      <td>0.8890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>nephew</td>\n",
       "      <td>N</td>\n",
       "      <td>0.9582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>.</td>\n",
       "      <td>,</td>\n",
       "      <td>0.9976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>@random</td>\n",
       "      <td>@</td>\n",
       "      <td>0.9960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word tag confidence\n",
       "0             My   D     0.9984\n",
       "1           name   N     0.9996\n",
       "2             is   V     0.9973\n",
       "3       Abhishek   ^     0.9628\n",
       "4              .   ,     0.9975\n",
       "5              I   O     0.9980\n",
       "6           have   V     0.9999\n",
       "7             no   D     0.9911\n",
       "8           clue   N     0.9998\n",
       "9              .   ,     0.9985\n",
       "10      Learning   V     0.9957\n",
       "11           the   D     0.9960\n",
       "12  back-portion   N     0.8394\n",
       "13          that   P     0.9530\n",
       "14             I   O     0.9989\n",
       "15         never   R     0.9922\n",
       "16         cared   V     0.9976\n",
       "17           for   P     0.9806\n",
       "18             .   ,     0.9916\n",
       "19       Obama's   Z     0.8890\n",
       "20        nephew   N     0.9582\n",
       "21             .   ,     0.9976\n",
       "22       @random   @     0.9960"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''tokenizer, and part-of-speech tagger from Carnegie Mellon\n",
    "created by Olutobi Owoputi, Brendan O'Connor, Kevin Gimpel, Nathan Schneider, Chris Dyer, Dipanjan Das, Daniel Mills, \n",
    "Jacob Eisenstein, Michael Heilman, Dani Yogatama, Jeffrey Flanigan, and Noah Smith'''\n",
    "'''RunTagger [options] [ExamplesFilename]\n",
    "  runs the CMU ARK Twitter tagger on tweets from ExamplesFilename, \n",
    "  writing taggings to standard output. Listens on stdin if no input filename.\n",
    "\n",
    "Options:\n",
    "  --model <Filename>        Specify model filename. (Else use built-in.)\n",
    "  --just-tokenize           Only run the tokenizer; no POS tags.\n",
    "  --quiet                   Quiet: no output\n",
    "  --input-format <Format>   Default: auto\n",
    "                            Options: json, text, conll\n",
    "  --output-format <Format>  Default: automatically decide from input format.\n",
    "                            Options: pretsv, conll\n",
    "  --input-field NUM         Default: 1\n",
    "                            Which tab-separated field contains the input\n",
    "                            (1-indexed, like unix 'cut')\n",
    "                            Only for {json, text} input formats.\n",
    "  --word-clusters <File>    Alternate word clusters file (see FeatureExtractor)\n",
    "  --no-confidence           Don't output confidence probabilities\n",
    "  --decoder <Decoder>       Change the decoding algorithm (default: greedy)\n",
    "\n",
    "Tweet-per-line input formats:\n",
    "   json: Every input line has a JSON object containing the tweet,\n",
    "         as per the Streaming API. (The 'text' field is used.)\n",
    "   text: Every input line has the text for one tweet.\n",
    "We actually assume input lines are TSV and the tweet data is one field.\n",
    "(Therefore tab characters are not allowed in tweets.\n",
    "Twitter's own JSON formats guarantee this;\n",
    "if you extract the text yourself, you must remove tabs and newlines.)\n",
    "Tweet-per-line output format is\n",
    "   pretsv: Prepend the tokenization and tagging as new TSV fields, \n",
    "           so the output includes a complete copy of the input.\n",
    "By default, three TSV fields are prepended:\n",
    "   Tokenization \\t POSTags \\t Confidences \\t (original data...)\n",
    "The tokenization and tags are parallel space-separated lists.\n",
    "The 'conll' format is token-per-line, blank spaces separating tweets.'''\n",
    "\n",
    "file = open(\"teststring.txt\", \"w\") \n",
    "file.write(teststring) \n",
    "file.close() \n",
    "\n",
    "#! ./ark-tweet-nlp-0.3.2/runTagger.sh ./ark-tweet-nlp-0.3.2/examples/example_tweets.txt\n",
    "#! ./ark-tweet-nlp-0.3.2/twokenize.sh --output-format pretsv ./ark-tweet-nlp-0.3.2/examples/casual.txt\n",
    "test1 = ! ./ark-tweet-nlp-0.3.2/runTagger.sh --output-format conll teststring.txt\n",
    "test1_list = list([re.split(r'([\\t])',x) for x in test1])\n",
    "test1_list = [[ item for item in word if item != '\\t' ] for word in test1_list]\n",
    "pd_test = pd.DataFrame(test1_list[1:-2], columns = ['word','tag','confidence'] )\n",
    "pd_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>target</th>\n",
       "      <th>text_tokcan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44893</th>\n",
       "      <td>Trump's tax cut won't be the biggest in U.S. h...</td>\n",
       "      <td>WASHINGTON (Reuters) - President Donald Trump ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>November 2, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>[washington, &lt;allcaps&gt;, (, reuters, ), -, pres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44894</th>\n",
       "      <td>U.S. House ethics panel investigating allegati...</td>\n",
       "      <td>WASHINGTON (Reuters) - The U.S. House of Repre...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>November 21, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>[washington, &lt;allcaps&gt;, (, reuters, ), -, the,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44895</th>\n",
       "      <td>U.S., EU set meeting on airline security, elec...</td>\n",
       "      <td>WASHINGTON/BRUSSELS (Reuters) - U.S. and Europ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>May 12, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>[washington, &lt;allcaps&gt;, /, brussels, &lt;allcaps&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44896</th>\n",
       "      <td>German coalition talks: 'Road to Jamaica is long'</td>\n",
       "      <td>BERLIN (Reuters) - German politicians seeking ...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>October 18, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>[berlin, &lt;allcaps&gt;, (, reuters, ), -, german, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44897</th>\n",
       "      <td>SAY WHAT? #BlackLivesMatter TEXTBOOKS TO BE US...</td>\n",
       "      <td>When will American citizens stop being afraid ...</td>\n",
       "      <td>politics</td>\n",
       "      <td>Aug 24, 2015</td>\n",
       "      <td>0</td>\n",
       "      <td>[when, will, american, citizens, stop, being, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "44893  Trump's tax cut won't be the biggest in U.S. h...   \n",
       "44894  U.S. House ethics panel investigating allegati...   \n",
       "44895  U.S., EU set meeting on airline security, elec...   \n",
       "44896  German coalition talks: 'Road to Jamaica is long'   \n",
       "44897  SAY WHAT? #BlackLivesMatter TEXTBOOKS TO BE US...   \n",
       "\n",
       "                                                    text       subject  \\\n",
       "44893  WASHINGTON (Reuters) - President Donald Trump ...  politicsNews   \n",
       "44894  WASHINGTON (Reuters) - The U.S. House of Repre...  politicsNews   \n",
       "44895  WASHINGTON/BRUSSELS (Reuters) - U.S. and Europ...  politicsNews   \n",
       "44896  BERLIN (Reuters) - German politicians seeking ...     worldnews   \n",
       "44897  When will American citizens stop being afraid ...      politics   \n",
       "\n",
       "                     date target  \\\n",
       "44893   November 2, 2017       1   \n",
       "44894  November 21, 2017       1   \n",
       "44895       May 12, 2017       1   \n",
       "44896   October 18, 2017       1   \n",
       "44897        Aug 24, 2015      0   \n",
       "\n",
       "                                             text_tokcan  \n",
       "44893  [washington, <allcaps>, (, reuters, ), -, pres...  \n",
       "44894  [washington, <allcaps>, (, reuters, ), -, the,...  \n",
       "44895  [washington, <allcaps>, /, brussels, <allcaps>...  \n",
       "44896  [berlin, <allcaps>, (, reuters, ), -, german, ...  \n",
       "44897  [when, will, american, citizens, stop, being, ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make new column with tokenized, canonicalized text\n",
    "all_data['text_tokcan'] = all_data['text'].apply(tokenize)\n",
    "all_data.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: 26 types\n",
      "26 words\n",
      "wordset:  ['<s>', '</s>', '<unk>', '.', 'i', 'my', 'name', 'is', 'abhishek', 'have', 'no', 'clue', 'learning', 'the', 'back', '-', 'portion', 'that', 'never', 'cared', 'for', 'obama', \"'\", 's', 'nephew', '<user>']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def build_vocab(corpus, V=None, **kw):\n",
    "    if isinstance(corpus, list):\n",
    "        token_feed = (utils.canonicalize_word(w) for w in corpus)\n",
    "        vocab = vocabulary.Vocabulary(token_feed, size=V, **kw)\n",
    "    print(\"Vocabulary: {:,} types\".format(vocab.size))\n",
    "    return vocab\n",
    "\n",
    "\n",
    "#utils.canonicalize_word(teststring.split())\n",
    "vocab=build_vocab(tokenize(teststring))\n",
    "print(\"{:,} words\".format(vocab.size))\n",
    "print(\"wordset: \",vocab.ordered_words())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / Dev / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split fractions add up to 1.0\n",
      "training set:  (31428, 6)\n",
      "dev set:  (6735, 6)\n",
      "test set:  (6735, 6)\n"
     ]
    }
   ],
   "source": [
    "#train/dev/train split\n",
    "#train_dev_split = 0.8\n",
    "\n",
    "train_fract = 0.70\n",
    "dev_fract = 0.15\n",
    "test_fract = 0.15\n",
    "\n",
    "if (train_fract+dev_fract+test_fract) == 1.0:\n",
    "    print('Split fractions add up to 1.0')\n",
    "else:\n",
    "    print('SPLIT FRACTIONS DO NOT ADD UP TO 1.0; PLEASE TRY AGAIN.............')\n",
    "\n",
    "#train_data = all_data[:int(len(all_data)*train_dev_split)].reset_index(drop=True)\n",
    "#dev_data = all_data[int(len(all_data)*train_dev_split):].reset_index(drop=True)\n",
    "\n",
    "train_set = all_data[ :int(len(all_data)*train_fract)].reset_index(drop=True)\n",
    "dev_set = all_data[int(len(all_data)*(train_fract)) : int(len(all_data)*(train_fract+dev_fract))].reset_index(drop=True)\n",
    "test_set = all_data[int(len(all_data)*(train_fract+dev_fract)) : ].reset_index(drop=True)\n",
    "\n",
    "print('training set: ',train_set.shape)\n",
    "print('dev set: ',dev_set.shape)\n",
    "print('test set: ',test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>target</th>\n",
       "      <th>text_tokcan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trump to nominate Raytheon lobbyist for Army s...</td>\n",
       "      <td>WASHINGTON (Reuters) - U.S. President Donald T...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>July 19, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>[washington, &lt;allcaps&gt;, (, reuters, ), -, u, ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thailand approves $2.2 billion in help for ric...</td>\n",
       "      <td>BANGKOK (Reuters) - Thailand s government on F...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>September 1, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>[bangkok, &lt;allcaps&gt;, (, reuters, ), -, thailan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>White House confident it will 'prevail' on tra...</td>\n",
       "      <td>ON BOARD AIR FORCE ONE (Reuters) - The White H...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>February 6, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>[on, &lt;allcaps&gt;, board, &lt;allcaps&gt;, air, &lt;allcap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Republican establishment bails on Alabama cand...</td>\n",
       "      <td>(Reuters) - The national campaign wing for U.S...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>November 10, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>[(, reuters, ), -, the, national, campaign, wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump’s Administration Was Just Caught Up In ...</td>\n",
       "      <td>While it can be said that no one is immune fro...</td>\n",
       "      <td>News</td>\n",
       "      <td>April 5, 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>[while, it, can, be, said, that, no, one, is, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Trump to nominate Raytheon lobbyist for Army s...   \n",
       "1  Thailand approves $2.2 billion in help for ric...   \n",
       "2  White House confident it will 'prevail' on tra...   \n",
       "3  Republican establishment bails on Alabama cand...   \n",
       "4   Trump’s Administration Was Just Caught Up In ...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  WASHINGTON (Reuters) - U.S. President Donald T...  politicsNews   \n",
       "1  BANGKOK (Reuters) - Thailand s government on F...     worldnews   \n",
       "2  ON BOARD AIR FORCE ONE (Reuters) - The White H...  politicsNews   \n",
       "3  (Reuters) - The national campaign wing for U.S...  politicsNews   \n",
       "4  While it can be said that no one is immune fro...          News   \n",
       "\n",
       "                 date target  \\\n",
       "0      July 19, 2017       1   \n",
       "1  September 1, 2017       1   \n",
       "2   February 6, 2017       1   \n",
       "3  November 10, 2017       1   \n",
       "4       April 5, 2017      0   \n",
       "\n",
       "                                         text_tokcan  \n",
       "0  [washington, <allcaps>, (, reuters, ), -, u, ....  \n",
       "1  [bangkok, <allcaps>, (, reuters, ), -, thailan...  \n",
       "2  [on, <allcaps>, board, <allcaps>, air, <allcap...  \n",
       "3  [(, reuters, ), -, the, national, campaign, wi...  \n",
       "4  [while, it, can, be, said, that, no, one, is, ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>target</th>\n",
       "      <th>text_tokcan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OBAMA TRIES TO CONDEMN TRUMP SUPPORTERS But Ge...</td>\n",
       "      <td>How dare Obama the worst president and most di...</td>\n",
       "      <td>politics</td>\n",
       "      <td>Mar 15, 2016</td>\n",
       "      <td>0</td>\n",
       "      <td>[how, dare, obama, the, worst, president, and,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Israeli ambassador backs Trump pledge to move ...</td>\n",
       "      <td>WASHINGTON (Reuters) - Israel’s ambassador to ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 21, 2016</td>\n",
       "      <td>1</td>\n",
       "      <td>[washington, &lt;allcaps&gt;, (, reuters, ), -, isra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BREAKING NEWS: RAND PAUL Has “Suspended” His C...</td>\n",
       "      <td>Sen. Rand Paul of Kentucky announced Wednesday...</td>\n",
       "      <td>politics</td>\n",
       "      <td>Feb 3, 2016</td>\n",
       "      <td>0</td>\n",
       "      <td>[sen, ., rand, paul, of, kentucky, announced, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Texas Newspapers Humiliate Ted Cruz By Endors...</td>\n",
       "      <td>Ted Cruz is so hated that even his home state ...</td>\n",
       "      <td>News</td>\n",
       "      <td>February 15, 2016</td>\n",
       "      <td>0</td>\n",
       "      <td>[ted, cruz, is, so, hated, that, even, his, ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEW DOCUMENTS: Hillary And State Department Ai...</td>\n",
       "      <td>Hillary Clinton and her aides must have felt l...</td>\n",
       "      <td>Government News</td>\n",
       "      <td>Aug 19, 2016</td>\n",
       "      <td>0</td>\n",
       "      <td>[hillary, clinton, and, her, aides, must, have...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  OBAMA TRIES TO CONDEMN TRUMP SUPPORTERS But Ge...   \n",
       "1  Israeli ambassador backs Trump pledge to move ...   \n",
       "2  BREAKING NEWS: RAND PAUL Has “Suspended” His C...   \n",
       "3   Texas Newspapers Humiliate Ted Cruz By Endors...   \n",
       "4  NEW DOCUMENTS: Hillary And State Department Ai...   \n",
       "\n",
       "                                                text          subject  \\\n",
       "0  How dare Obama the worst president and most di...         politics   \n",
       "1  WASHINGTON (Reuters) - Israel’s ambassador to ...     politicsNews   \n",
       "2  Sen. Rand Paul of Kentucky announced Wednesday...         politics   \n",
       "3  Ted Cruz is so hated that even his home state ...             News   \n",
       "4  Hillary Clinton and her aides must have felt l...  Government News   \n",
       "\n",
       "                 date target  \\\n",
       "0        Mar 15, 2016      0   \n",
       "1  December 21, 2016       1   \n",
       "2         Feb 3, 2016      0   \n",
       "3   February 15, 2016      0   \n",
       "4        Aug 19, 2016      0   \n",
       "\n",
       "                                         text_tokcan  \n",
       "0  [how, dare, obama, the, worst, president, and,...  \n",
       "1  [washington, <allcaps>, (, reuters, ), -, isra...  \n",
       "2  [sen, ., rand, paul, of, kentucky, announced, ...  \n",
       "3  [ted, cruz, is, so, hated, that, even, his, ho...  \n",
       "4  [hillary, clinton, and, her, aides, must, have...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_set.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>target</th>\n",
       "      <th>text_tokcan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dad Of Murdered Reporter Hits Trump, GOP BEAU...</td>\n",
       "      <td>The father of a Virginia reporter who was shot...</td>\n",
       "      <td>News</td>\n",
       "      <td>August 27, 2016</td>\n",
       "      <td>0</td>\n",
       "      <td>[the, father, of, a, virginia, reporter, who, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vote recount effort races forward despite Trum...</td>\n",
       "      <td>WASHINGTON (Reuters) - Donald Trump’s transiti...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>November 28, 2016</td>\n",
       "      <td>1</td>\n",
       "      <td>[washington, &lt;allcaps&gt;, (, reuters, ), -, dona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Boiler Room EP #119 – Zombie Disneyland &amp; The ...</td>\n",
       "      <td>Tune in to the Alternate Current Radio Network...</td>\n",
       "      <td>US_News</td>\n",
       "      <td>July 29, 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>[tune, in, to, the, alternate, current, radio,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump National Security Pick Monica Crowley’s...</td>\n",
       "      <td>Conservative columnist Monica Crowley is set f...</td>\n",
       "      <td>News</td>\n",
       "      <td>January 10, 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>[conservative, columnist, monica, crowley, is,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stock futures dip after North Korea nuclear test</td>\n",
       "      <td>NEW YORK (Reuters) - U.S. equity index futures...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>September 3, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>[new, &lt;allcaps&gt;, york, &lt;allcaps&gt;, (, reuters, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Dad Of Murdered Reporter Hits Trump, GOP BEAU...   \n",
       "1  Vote recount effort races forward despite Trum...   \n",
       "2  Boiler Room EP #119 – Zombie Disneyland & The ...   \n",
       "3   Trump National Security Pick Monica Crowley’s...   \n",
       "4   Stock futures dip after North Korea nuclear test   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  The father of a Virginia reporter who was shot...          News   \n",
       "1  WASHINGTON (Reuters) - Donald Trump’s transiti...  politicsNews   \n",
       "2  Tune in to the Alternate Current Radio Network...       US_News   \n",
       "3  Conservative columnist Monica Crowley is set f...          News   \n",
       "4  NEW YORK (Reuters) - U.S. equity index futures...     worldnews   \n",
       "\n",
       "                 date target  \\\n",
       "0     August 27, 2016      0   \n",
       "1  November 28, 2016       1   \n",
       "2       July 29, 2017      0   \n",
       "3    January 10, 2017      0   \n",
       "4  September 3, 2017       1   \n",
       "\n",
       "                                         text_tokcan  \n",
       "0  [the, father, of, a, virginia, reporter, who, ...  \n",
       "1  [washington, <allcaps>, (, reuters, ), -, dona...  \n",
       "2  [tune, in, to, the, alternate, current, radio,...  \n",
       "3  [conservative, columnist, monica, crowley, is,...  \n",
       "4  [new, <allcaps>, york, <allcaps>, (, reuters, ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model: Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify full text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data shape: (31428,)\n",
      "['WASHINGTON (Reuters) - U.S. President Donald Trump intends to nominate a Raytheon Co (RTN.N) lobbyist, Mark Esper, for the position of secretary of the Army, the White House said on Wednesday. The position has been challenging for Trump to fill. Two previous nominees withdrew their names from consideration. Before Esper joined U.S. missile maker Raytheon in 2010 as vice president government relations he held posts at industry advocacy groups like the Aerospace Industries Association and the U.S. Chamber of Commerce. Esper graduated from the United States Military Academy at West Point, retired from the U.S. Army as a lieutenant colonel and is a veteran of the Gulf War, according to a Raytheon memo announcing his hiring. ']\n",
      "\n",
      "train_labels shape: (31428,)\n",
      "[1 1 1 ... 1 0 0]\n",
      "<class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *\n",
    "#from sklearn.grid_search import GridSearchCV   # THIS HAS BEEN DEPRECATED\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "train_data, train_labels = train_set.text.values, train_set.target.values\n",
    "dev_data, dev_labels = dev_set.text.values, dev_set.target.values\n",
    "\n",
    "train_labels = train_labels.astype(int)\n",
    "dev_labels = dev_labels.astype(int)\n",
    "\n",
    "print('train_data shape:', train_data.shape)\n",
    "#print(train_data[0].shape)\n",
    "print(train_data[:1])\n",
    "print('\\ntrain_labels shape:', train_labels.shape)\n",
    "print(train_labels)\n",
    "print(type(train_labels[0]))\n",
    "#train_labels.head()\n",
    "#dev_data.head()\n",
    "#dev_labels.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<31428x104692 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 6562980 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(train_data)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (31428, 104692)\n",
      "Vocabulary size (number of features or columns): 104692\n",
      "Non-zero elements in matrix (X.nnz): 6562980\n",
      "Average number of non-zero features per example (per document): 208.826\n",
      "Fraction of non-zero elements in matrix: 0.0020\n",
      "0th feature string: 00\n",
      "last feature string: zzzzaaaacccchhh\n"
     ]
    }
   ],
   "source": [
    "print('X.shape:', X.shape) # (). There are x documents (rows) in the corpus, with y features (unique words = vocabulary)\n",
    "print('Vocabulary size (number of features or columns):', X.shape[1])  # \n",
    "print('Non-zero elements in matrix (X.nnz):', X.nnz)   # This indicates that there are z non-zero elements in the matrix.\n",
    "print('Average number of non-zero features per example (per document): %.3f' %(X.nnz/X.shape[0]))  # non-zero elements in matrix / documents = xxx\n",
    "print('Fraction of non-zero elements in matrix: %.4f' %( X.nnz/(X.shape[0] * X.shape[1])) )   # Fraction of entries in the matrix that are non-zero = X.nnz/(rows*columns) = 0.xxx \n",
    "\n",
    "\n",
    "# What are the 0th and last feature strings (in alphabetical order)?\n",
    "print('0th feature string:', vectorizer.get_feature_names()[0])   # \n",
    "print('last feature string:', vectorizer.get_feature_names()[X.shape[1]-1])    # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_dev.shape: (6735, 53996)\n",
      "Vocabulary using train data: 104692\n",
      "Vocabulary using dev data: 53996\n",
      "X_dev_transformed shape: (6735, 104692)\n",
      "Count of words (features) in X_dev also in X: 44685\n",
      "Fraction of words in dev data missing from training vocabulary: 0.172\n"
     ]
    }
   ],
   "source": [
    "# Using the standard CountVectorizer, what fraction of the words in the dev data are missing from the vocabulary? \n",
    "vectorizer_dev = CountVectorizer()\n",
    "X_dev = vectorizer_dev.fit_transform(dev_data)  # Independently build a vocabulary using dev_data.\n",
    "print('X_dev.shape:', X_dev.shape)\n",
    "print('Vocabulary using train data:', X.shape[1])  # \n",
    "print('Vocabulary using dev data:', X_dev.shape[1])                # \n",
    "\n",
    "# Feed dev_data into the vectorizer fit using training data.\n",
    "X_dev_transformed = vectorizer.transform(dev_data)\n",
    "print('X_dev_transformed shape:', X_dev_transformed.shape)\n",
    "#print('X_dev_transformed.shape', X_dev_transformed.shape)  # (676, 26,879)  EXPECT .shape[1] equal to original number of features\n",
    "#print('non-zero indices in X_dev_transformed:', X_dev_transformed.nonzero())  # could also use this to check which features missing...\n",
    "\n",
    "''' This is way too slow; use set intersection instead!!\n",
    "# Look at each feature (vocabulary word) in X_dev and see if it is a feature in X.\n",
    "count = 0\n",
    "for i in range(X_dev.shape[1]):\n",
    "    if vectorizer_dev.get_feature_names()[i] in vectorizer.get_feature_names():\n",
    "        count += 1\n",
    "print('Count of words (features) in X_dev also in X:', count)   \n",
    "print('Fraction of words in dev data missing from training vocabulary: %.3f' %((X_dev.shape[1] - count)/X_dev.shape[1]) )\n",
    "count of words (features) in X_dev also in X: 12219\n",
    "Fraction of words in dev data missing from training vocabulary: 0.248\n",
    "'''\n",
    "\n",
    "set1 = set(vectorizer_dev.get_feature_names())\n",
    "set2 = set(vectorizer.get_feature_names())\n",
    "print('Count of words (features) in X_dev also in X:', len(set1.intersection(set2)))\n",
    "print('Fraction of words in dev data missing from training vocabulary: %.3f' %((X_dev.shape[1] - len(set1.intersection(set2)))/X_dev.shape[1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB\n",
      "accuracy: 0.94\n"
     ]
    }
   ],
   "source": [
    "# BernoulliNB\n",
    "print('BernoulliNB')\n",
    "alpha = 1\n",
    "clf = BernoulliNB(alpha=alpha)\n",
    "clf.fit(X, train_labels)\n",
    "\n",
    "print('accuracy: %3.2f' %clf.score(X_dev_transformed, dev_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Fit a Multinomial Naive Bayes model and find the optimal value for alpha\n",
    "\n",
    "cv_params = {'alpha': [1E-10, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]}\n",
    "mnb = GridSearchCV(estimator=MultinomialNB(), param_grid=cv_params, scoring='f1_weighted', cv=10, n_jobs=-1)\n",
    "mnb.fit(X, train_labels)  \n",
    "\n",
    "print('\\nMultinomial Naive Bayes best GridSearchCV results:')\n",
    "print('Best params:', mnb.best_params_)\n",
    "print('Best score: %.3f' %(mnb.best_score_))\n",
    "#print('Best estimator: \\n', mnb.best_estimator_)\n",
    "\n",
    "mnb_dev_predicted_labels = mnb.predict(X_dev_transformed)  # \"predict\" and report accuracy using dev set\n",
    "print('f1 score of dev predicted labels using Multinominal Naive Bayes: %.3f' %(metrics.f1_score(dev_labels, mnb_dev_predicted_labels, average='weighted')))\n",
    "#print('classification report of dev predicted labels: \\n', classification_report(dev_labels, mnb_dev_predicted_labels))\n",
    "print()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB with TfidfVectorizer\n",
      "accuracy: 0.94\n",
      "\n",
      "f1 score of dev predicted labels: 0.9419881828992114\n",
      "classification report of dev predicted labels: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94      3552\n",
      "           1       0.92      0.96      0.94      3183\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      6735\n",
      "   macro avg       0.94      0.94      0.94      6735\n",
      "weighted avg       0.94      0.94      0.94      6735\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Convert a collection of raw documents to a matrix of TF-IDF features.\n",
    "Equivalent to CountVectorizer followed by TfidfTransformer.\n",
    "\n",
    "In a large text corpus, some words will be very present (e.g. “the”, “a”, “is” in English) hence carrying very little \n",
    "meaningful information about the actual contents of the document. If we were to feed the direct count data directly to \n",
    "a classifier those very frequent terms would shadow the frequencies of rarer yet more interesting terms.\n",
    "\n",
    "In order to re-weight the count features into floating point values suitable for usage by a classifier it is very \n",
    "common to use the tf–idf transform.\n",
    "\n",
    "Tf means term-frequency while tf–idf means term-frequency times inverse document-frequency: \n",
    "\\text{tf-idf(t,d)}=\\text{tf(t,d)} \\times \\text{idf(t)}.\n",
    "'''\n",
    "\n",
    "t_vectorizer = TfidfVectorizer()\n",
    "t_X = t_vectorizer.fit_transform(train_data)   \n",
    "#print(t_X.shape)\n",
    "t_X_dev = t_vectorizer.transform(dev_data)\n",
    "#print(t_X_dev.shape)\n",
    "\n",
    "\n",
    "# BernoulliNB\n",
    "print('BernoulliNB with TfidfVectorizer')\n",
    "alpha = 1\n",
    "t_clf = BernoulliNB(alpha=alpha)\n",
    "t_clf.fit(t_X, train_labels)\n",
    "\n",
    "print('accuracy: %3.2f' %t_clf.score(t_X_dev, dev_labels))\n",
    "\n",
    "t_dev_predicted_labels = t_clf.predict(t_X_dev)  # \"predict\" and report accuracy using dev set\n",
    "#print(t_dev_predicted_labels.shape)\n",
    "\n",
    "print('\\nf1 score of dev predicted labels:', metrics.f1_score(dev_labels, t_dev_predicted_labels, average='weighted'))\n",
    "print('classification report of dev predicted labels: \\n', classification_report(dev_labels, t_dev_predicted_labels))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Same results (accuracy=0.94) for both the default CountVectorizer and TfidfVectorizer.  Using full text means all TRUE news contains the word \"Reuters\", which is an unfair advantage.  Will try to remove those and run again, expecting lower accuracy.  \n",
    "Should also account for text starting with: \"'The following statements\\xa0were posted to the verified Twitter accounts of U.S. President Donald Trump, @realDonaldTrump and @POTUS.  The opinions expressed are his own.\\xa0Reuters has not edited the statements or confirmed their accuracy.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat Naive Bayes on text field after removing first chunk of text, including \"Reuters\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3  FBI Russia probe helped by Australian diplomat...   \n",
       "4  Trump wants Postal Service to charge 'much mor...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
       "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
       "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
       "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
       "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
       "\n",
       "                 date target  \n",
       "0  December 31, 2017       1  \n",
       "1  December 29, 2017       1  \n",
       "2  December 31, 2017       1  \n",
       "3  December 30, 2017       1  \n",
       "4  December 29, 2017       1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The head of a conservative Republican faction in the U.S. Congress, who voted this month for a huge expansion of the national debt to pay for tax cuts, called himself a “fiscal conservative” on Sunday and urged budget restraint in 2018. In keeping with a sharp pivot under way among Republicans, U.S. Representative Mark Meadows, speaking on CBS’ “Face the Nation,” drew a hard line on federal spending, which lawmakers are bracing to do battle over in January. When they return from the holidays on Wednesday, lawmakers will begin trying to pass a federal budget in a fight likely to be linked to other issues, such as immigration policy, even as the November congressional election campaigns approach in which Republicans will seek to keep control of Congress. President Donald Trump and his Republicans want a big budget increase in military spending, while Democrats also want proportional increases for non-defense “discretionary” spending on programs that support education, scientific research, infrastructure, public health and environmental protection. “The (Trump) administration has already been willing to say: ‘We’re going to increase non-defense discretionary spending ... by about 7 percent,’” Meadows, chairman of the small but influential House Freedom Caucus, said on the program. “Now, Democrats are saying that’s not enough, we need to give the government a pay raise of 10 to 11 percent. For a fiscal conservative, I don’t see where the rationale is. ... Eventually you run out of other people’s money,” he said. Meadows was among Republicans who voted in late December for their party’s debt-financed tax overhaul, which is expected to balloon the federal budget deficit and add about $1.5 trillion over 10 years to the $20 trillion national debt. “It’s interesting to hear Mark talk about fiscal responsibility,” Democratic U.S. Representative Joseph Crowley said on CBS. Crowley said the Republican tax bill would require the  United States to borrow $1.5 trillion, to be paid off by future generations, to finance tax cuts for corporations and the rich. “This is one of the least ... fiscally responsible bills we’ve ever seen passed in the history of the House of Representatives. I think we’re going to be paying for this for many, many years to come,” Crowley said. Republicans insist the tax package, the biggest U.S. tax overhaul in more than 30 years,  will boost the economy and job growth. House Speaker Paul Ryan, who also supported the tax bill, recently went further than Meadows, making clear in a radio interview that welfare or “entitlement reform,” as the party often calls it, would be a top Republican priority in 2018. In Republican parlance, “entitlement” programs mean food stamps, housing assistance, Medicare and Medicaid health insurance for the elderly, poor and disabled, as well as other programs created by Washington to assist the needy. Democrats seized on Ryan’s early December remarks, saying they showed Republicans would try to pay for their tax overhaul by seeking spending cuts for social programs. But the goals of House Republicans may have to take a back seat to the Senate, where the votes of some Democrats will be needed to approve a budget and prevent a government shutdown. Democrats will use their leverage in the Senate, which Republicans narrowly control, to defend both discretionary non-defense programs and social spending, while tackling the issue of the “Dreamers,” people brought illegally to the country as children. Trump in September put a March 2018 expiration date on the Deferred Action for Childhood Arrivals, or DACA, program, which protects the young immigrants from deportation and provides them with work permits. The president has said in recent Twitter messages he wants funding for his proposed Mexican border wall and other immigration law changes in exchange for agreeing to help the Dreamers. Representative Debbie Dingell told CBS she did not favor linking that issue to other policy objectives, such as wall funding. “We need to do DACA clean,” she said.  On Wednesday, Trump aides will meet with congressional leaders to discuss those issues. That will be followed by a weekend of strategy sessions for Trump and Republican leaders on Jan. 6 and 7, the White House said. Trump was also scheduled to meet on Sunday with Florida Republican Governor Rick Scott, who wants more emergency aid. The House has passed an $81 billion aid package after hurricanes in Florida, Texas and Puerto Rico, and wildfires in California. The package far exceeded the $44 billion requested by the Trump administration. The Senate has not yet voted on the aid. '"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_data.iloc[0,1][22:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        WASHINGTON (Reuters) - The head of a conservat...\n",
       "1        WASHINGTON (Reuters) - Transgender people will...\n",
       "2        WASHINGTON (Reuters) - The special counsel inv...\n",
       "3        WASHINGTON (Reuters) - Trump campaign adviser ...\n",
       "4        SEATTLE/WASHINGTON (Reuters) - President Donal...\n",
       "5        WEST PALM BEACH, Fla./WASHINGTON (Reuters) - T...\n",
       "6        WEST PALM BEACH, Fla (Reuters) - President Don...\n",
       "7        The following statements were posted to the ve...\n",
       "8        The following statements were posted to the ve...\n",
       "9        WASHINGTON (Reuters) - Alabama Secretary of St...\n",
       "10       (Reuters) - Alabama officials on Thursday cert...\n",
       "11       NEW YORK/WASHINGTON (Reuters) - The new U.S. t...\n",
       "12       The following statements were posted to the ve...\n",
       "13       The following statements were posted to the ve...\n",
       "14        (In Dec. 25 story, in second paragraph, corre...\n",
       "15       (Reuters) - A lottery drawing to settle a tied...\n",
       "16       WASHINGTON (Reuters) - A Georgian-American bus...\n",
       "17       The following statements were posted to the ve...\n",
       "18       (Reuters) - A U.S. appeals court in Washington...\n",
       "19       (Reuters) - A gift-wrapped package addressed t...\n",
       "20       WASHINGTON (Reuters) - A federal judge in Seat...\n",
       "21       NEW YORK (Reuters) - The U.S. Justice Departme...\n",
       "22       (Reuters) - A U.S. appeals court on Friday sai...\n",
       "23       WASHINGTON (Reuters) - A federal appeals court...\n",
       "24       LIMA (Reuters) - Peru’s President Pedro Pablo ...\n",
       "25       WASHINGTON (Reuters) - U.S. President Donald T...\n",
       "26       WASHINGTON (Reuters) - U.S. financial regulato...\n",
       "27       The following statements were posted to the ve...\n",
       "28       MEXICO CITY (Reuters) - Mexico’s finance minis...\n",
       "29       WASHINGTON (Reuters) - U.S. Senate Majority Le...\n",
       "                               ...                        \n",
       "21387    TRIPOLI (Reuters) - Former Libyan Prime Minist...\n",
       "21388    LONDON (Reuters) - Britain on Wednesday outlin...\n",
       "21389    BERLIN (Reuters) - Chancellor Angela Merkel sa...\n",
       "21390    KARACHI, Pakistan (Reuters) - Pakistan has rej...\n",
       "21391    BUCHAREST (Reuters) - Romania s justice minist...\n",
       "21392    BEIRUT (Reuters) - Iran and Saudi Arabia will ...\n",
       "21393    COPENHAGEN (Reuters) - Police on Wednesday ide...\n",
       "21394    HONG KONG (Reuters) - Typhoon Hato, a maximum ...\n",
       "21395    WARSAW (Reuters) - Poland will allocate an add...\n",
       "21396    DUBAI (Reuters) - Fighters loyal to the armed ...\n",
       "21397    BERLIN (Reuters) - The leader of Germany s Soc...\n",
       "21398    SHANGHAI (Reuters) - An old review of an acade...\n",
       "21399    DUBAI (Reuters) - A 14-year-old boy who was de...\n",
       "21400    LONDON (Reuters) - Abdul Daoud spilt most of t...\n",
       "21401    BUENOS AIRES (Reuters) - Argentina s main labo...\n",
       "21402    ON BOARD A U.S. MILITARY AIRCRAFT (Reuters) - ...\n",
       "21403    WASHINGTON (Reuters) - The United States sugge...\n",
       "21404    WASHINGTON (Reuters) - The United States has d...\n",
       "21405    ISLAMABAD (Reuters) - Outlining a new strategy...\n",
       "21406    GENEVA (Reuters) - North Korea and the United ...\n",
       "21407    SAO PAULO (Reuters) - Cesar Mata Pires, the ow...\n",
       "21408    GENEVA (Reuters) - North Korea and the United ...\n",
       "21409    GENEVA (Reuters) - North Korea and the United ...\n",
       "21410    COPENHAGEN (Reuters) - Danish police said on T...\n",
       "21411    UNITED NATIONS (Reuters) - Two North Korean sh...\n",
       "21412    BRUSSELS (Reuters) - NATO allies on Tuesday we...\n",
       "21413    LONDON (Reuters) - LexisNexis, a provider of l...\n",
       "21414    MINSK (Reuters) - In the shadow of disused Sov...\n",
       "21415    MOSCOW (Reuters) - Vatican Secretary of State ...\n",
       "21416    JAKARTA (Reuters) - Indonesia will buy 11 Sukh...\n",
       "Name: text, Length: 21417, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_data.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_data2 = true_data.iloc[:,1][22:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22    (Reuters) - A U.S. appeals court on Friday sai...\n",
       "23    WASHINGTON (Reuters) - A federal appeals court...\n",
       "24    LIMA (Reuters) - Peru’s President Pedro Pablo ...\n",
       "25    WASHINGTON (Reuters) - U.S. President Donald T...\n",
       "26    WASHINGTON (Reuters) - U.S. financial regulato...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: Didn't do what was intended.  Will need to step through each line one at a time, look for \"Reuters\" and \"The following statements...\" and remove these..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append the datasets and shuffle them\n",
    "all_data2 = true_data2.append(fake_data, ignore_index=True)\n",
    "all_data2 = all_data2.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "all_data2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Naive Bayes on the Title field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Donald Trump Sends Out Embarrassing New Year’...\n",
       "1         Drunk Bragging Trump Staffer Started Russian ...\n",
       "2         Sheriff David Clarke Becomes An Internet Joke...\n",
       "3         Trump Is So Obsessed He Even Has Obama’s Name...\n",
       "4         Pope Francis Just Called Out Donald Trump Dur...\n",
       "5         Racist Alabama Cops Brutalize Black Boy While...\n",
       "6         Fresh Off The Golf Course, Trump Lashes Out A...\n",
       "7         Trump Said Some INSANELY Racist Stuff Inside ...\n",
       "8         Former CIA Director Slams Trump Over UN Bully...\n",
       "9         WATCH: Brand-New Pro-Trump Ad Features So Muc...\n",
       "10        Papa John’s Founder Retires, Figures Out Raci...\n",
       "11        WATCH: Paul Ryan Just Told Us He Doesn’t Care...\n",
       "12        Bad News For Trump — Mitch McConnell Says No ...\n",
       "13        WATCH: Lindsey Graham Trashes Media For Portr...\n",
       "14        Heiress To Disney Empire Knows GOP Scammed Us...\n",
       "15        Tone Deaf Trump: Congrats Rep. Scalise On Los...\n",
       "16        The Internet Brutally Mocks Disney’s New Trum...\n",
       "17        Mueller Spokesman Just F-cked Up Donald Trump...\n",
       "18        SNL Hilariously Mocks Accused Child Molester ...\n",
       "19        Republican Senator Gets Dragged For Going Aft...\n",
       "20        In A Heartless Rebuke To Victims, Trump Invit...\n",
       "21        KY GOP State Rep. Commits Suicide Over Allega...\n",
       "22        Meghan McCain Tweets The Most AMAZING Respons...\n",
       "23        CNN CALLS IT: A Democrat Will Represent Alaba...\n",
       "24        White House: It Wasn’t Sexist For Trump To Sl...\n",
       "25        Despicable Trump Suggests Female Senator Woul...\n",
       "26        Accused Child Molesting Senate Candidate Roy ...\n",
       "27        WATCH: Fox Host Calls For A ‘Cleansing’ Of Th...\n",
       "28        Liberal Group Trolls Trump At Roy Moore Rally...\n",
       "29        Don Jr. Tries To Mock Al Franken’s Resignatio...\n",
       "                               ...                        \n",
       "23451    3.57 Degrees: Kevin Bacon’s Cultural Mantle Sh...\n",
       "23452             Bernie Sanders Could End Up Winning Iowa\n",
       "23453    Plastic Persona: Behind the Scenes of the Ted ...\n",
       "23454            ‘Meet Jeb’ – Going For Your Sympathy Vote\n",
       "23455    BOILER ROOM – Examination, Exclamation, Excita...\n",
       "23456    Eyewash: CIA Elites Misleading Employees Indic...\n",
       "23457    Activist: ‘This is where you can make the most...\n",
       "23458    Episode #120 – SUNDAY WIRE: ‘Crisis of Liberty...\n",
       "23459    FBI Release Oregon Video Footage Depicting Dea...\n",
       "23460    Trial By YouTube: Mainstream Media Use Second-...\n",
       "23461    REPORT: ‘Federal Government Escalated the Viol...\n",
       "23462    BOILER ROOM – Oregon Standoff, Cuddle Parties,...\n",
       "23463    Eyewitness Says Feds Ambushed Bundys, 100 Shot...\n",
       "23464    Episode #119 – SUNDAY WIRE: ‘You Know the Dril...\n",
       "23465    ‘There’ll be boots on the ground’: US making n...\n",
       "23466    Boston Brakes? How to Hack a New Car With Your...\n",
       "23467    Oregon Governor Says Feds ‘Must Act’ Against P...\n",
       "23468    Ron Paul on Burns Oregon Standoff and Jury Nul...\n",
       "23469       BOILER ROOM: As the Frogs Slowly Boil – EP #40\n",
       "23470    Arizona Rancher Protesting in Oregon is Target...\n",
       "23471    Seven Iranians freed in the prisoner swap have...\n",
       "23472                        #Hashtag Hell & The Fake Left\n",
       "23473    Astroturfing: Journalist Reveals Brainwashing ...\n",
       "23474            The New American Century: An Era of Fraud\n",
       "23475    Hillary Clinton: ‘Israel First’ (and no peace ...\n",
       "23476    McPain: John McCain Furious That Iran Treated ...\n",
       "23477    JUSTICE? Yahoo Settles E-mail Privacy Class-ac...\n",
       "23478    Sunnistan: US and Allied ‘Safe Zone’ Plan to T...\n",
       "23479    How to Blow $700 Million: Al Jazeera America F...\n",
       "23480    10 U.S. Navy Sailors Held by Iranian Military ...\n",
       "Name: title, Length: 23481, dtype: object"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_data.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data shape: (31428,)\n",
      "['Trump to nominate Raytheon lobbyist for Army secretary']\n",
      "\n",
      "train_labels shape: (31428,)\n",
      "[1 1 1 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "train_data, train_labels = train_set.title.values, train_set.target.values\n",
    "dev_data, dev_labels = dev_set.title.values, dev_set.target.values\n",
    "\n",
    "train_labels = train_labels.astype(int)\n",
    "dev_labels = dev_labels.astype(int)\n",
    "\n",
    "#train_data.head()\n",
    "print('train_data shape:', train_data.shape)\n",
    "#print(train_data[0].shape)\n",
    "print(train_data[:1])\n",
    "print('\\ntrain_labels shape:', train_labels.shape)\n",
    "print(train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (31428, 18850)\n",
      "Vocabulary size (number of features or columns): 18850\n",
      "Non-zero elements in matrix (X.nnz): 382587\n",
      "Average number of non-zero features per example (per document): 12.173\n",
      "Fraction of non-zero elements in matrix: 0.0006\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(train_data)\n",
    "\n",
    "\n",
    "print('X.shape:', X.shape) # (). There are x documents (rows) in the corpus, with y features (unique words = vocabulary)\n",
    "print('Vocabulary size (number of features or columns):', X.shape[1])  # \n",
    "print('Non-zero elements in matrix (X.nnz):', X.nnz)   # This indicates that there are z non-zero elements in the matrix.\n",
    "print('Average number of non-zero features per example (per document): %.3f' %(X.nnz/X.shape[0]))  # non-zero elements in matrix / documents = xxx\n",
    "print('Fraction of non-zero elements in matrix: %.4f' %( X.nnz/(X.shape[0] * X.shape[1])) )   # Fraction of entries in the matrix that are non-zero = X.nnz/(rows*columns) = 0.xxx \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_dev.shape: (6735, 10434)\n",
      "Vocabulary using train data: 18850\n",
      "Vocabulary using dev data: 10434\n",
      "X_dev_transformed shape: (6735, 18850)\n",
      "Count of words (features) in X_dev also in X: 9303\n",
      "Fraction of words in dev data missing from training vocabulary: 0.108\n"
     ]
    }
   ],
   "source": [
    "# Using the standard CountVectorizer, what fraction of the words in the dev data are missing from the vocabulary? \n",
    "vectorizer_dev = CountVectorizer()\n",
    "X_dev = vectorizer_dev.fit_transform(dev_data)  # Independently build a vocabulary using dev_data.\n",
    "print('X_dev.shape:', X_dev.shape)\n",
    "print('Vocabulary using train data:', X.shape[1])  # \n",
    "print('Vocabulary using dev data:', X_dev.shape[1])                # \n",
    "\n",
    "# Feed dev_data into the vectorizer fit using training data.\n",
    "X_dev_transformed = vectorizer.transform(dev_data)\n",
    "print('X_dev_transformed shape:', X_dev_transformed.shape)\n",
    "#print('X_dev_transformed.shape', X_dev_transformed.shape)  # ()  EXPECT .shape[1] equal to original number of features\n",
    "#print('non-zero indices in X_dev_transformed:', X_dev_transformed.nonzero())  # could also use this to check which features missing...\n",
    "\n",
    "''' This is way too slow; use set intersection instead!!\n",
    "# Look at each feature (vocabulary word) in X_dev and see if it is a feature in X.\n",
    "count = 0\n",
    "for i in range(X_dev.shape[1]):\n",
    "    if vectorizer_dev.get_feature_names()[i] in vectorizer.get_feature_names():\n",
    "        count += 1\n",
    "print('Count of words (features) in X_dev also in X:', count)   \n",
    "print('Fraction of words in dev data missing from training vocabulary: %.3f' %((X_dev.shape[1] - count)/X_dev.shape[1]) )\n",
    "count of words (features) in X_dev also in X: 12219\n",
    "Fraction of words in dev data missing from training vocabulary: 0.248\n",
    "'''\n",
    "\n",
    "set1 = set(vectorizer_dev.get_feature_names())\n",
    "set2 = set(vectorizer.get_feature_names())\n",
    "print('Count of words (features) in X_dev also in X:', len(set1.intersection(set2)))\n",
    "print('Fraction of words in dev data missing from training vocabulary: %.3f' %((X_dev.shape[1] - len(set1.intersection(set2)))/X_dev.shape[1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB\n",
      "accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "# BernoulliNB\n",
    "print('BernoulliNB')\n",
    "alpha = 1\n",
    "clf = BernoulliNB(alpha=alpha)\n",
    "clf.fit(X, train_labels)\n",
    "\n",
    "print('accuracy: %3.2f' %clf.score(X_dev_transformed, dev_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title, target label\n",
      "  Trump’s Administration Was Just Caught Up In Prostitution Scandal; Here’s How It Went Down (DETAILS) 0\n"
     ]
    }
   ],
   "source": [
    "#print('title, target label\\n', train_set.title, train_set.target)\n",
    "print('title, target label\\n', train_set.title[4], train_set.target[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_set.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sandbox\n",
    "\n",
    "delete eveything below when notebook complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NEW DELHI (Reuters) - Donald Trump sympathizes with India in its recent escalation of tensions with Pakistan and supports skilled immigration, an adviser said on Friday, portraying the U.S. presidential hopeful as a friend of India and Indian Americans. Trump, a real estate billionaire, has earned a reputation of hostility toward minorities with proposals such as “extreme vetting” of potential immigrants and building a wall along the Mexican border to stop illegal immigration.  The Republican nominee has proposed a ban on immigration from countries where vetting would be difficult, such as nations faced with Islamic militancy. Some Indian officials worry the United States could become more isolationist under Trump, leaving allies like New Delhi without the support it has enjoyed under President Barack Obama against China’s growing regional influence.      Shalabh Kumar, a Chicago-based businessman of Indian origin tasked by the Trump campaign with reaching out to Asian-Americans, said India and the Indian-American community had nothing to fear from a Trump presidency.    There may be only 4 million Indian Americans but the potential to develop the relationship with their country of origin, a land of 1.3 billion, was huge, Kumar told a news conference at a hotel in New Delhi that drew a curious audience of about 30 journalists and several TV cameras. “Our overarching goal is for the 21st century to be an Indian-American century - instead of a Sino-American century,” said Kumar, wearing a dark suit and gold-rimmed pilot glasses, his white hair swept back.     “Mr Trump is a businessman - he has no bone in his body, not a drop of blood that is anti-immigrant,” Kumar said. “He wants to have legal, skills-based immigration.” The Punjabi-born businessman, who emigrated in 1969 and was converted to the Republican cause by Ronald Reagan, also said Trump’s determination to keep Islamic militants out of the United States played well with his community.  Around four in five Indians profess the Hindu faith, while 14 percent are Muslims. Hindu nationalist groups, including many Indian Americans, have applauded Trump’s anti-Muslim comments. “There is a war declared on the free world by Islamic terrorists,” Kumar said. “We are very happy that India under Prime Minister Narendra Modi has taken a very firm stand.” Kumar said the Republican Hindu Coalition, a group that he set up last year, would hold a cultural event and charity fundraiser in New Jersey on Oct. 15 at which Trump will deliver a keynote address. Half of the gate receipts would go to victims of terrorism, in particular Hindu refugees from Kashmir and Bangladesh. '"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.DataFrame([[1, 2], [3, 4]], columns=list('AB'))\n",
    "#df2 = pd.DataFrame([[5, 6], [7, 8]], columns=list('AB'))\n",
    "\n",
    "\n",
    "\n",
    "all_data.iloc[1]['text']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Detected',\n",
       " ' ',\n",
       " 'text',\n",
       " ' ',\n",
       " 'input',\n",
       " ' ',\n",
       " 'format',\n",
       " 'My',\n",
       " '\\t',\n",
       " 'D',\n",
       " '\\t',\n",
       " '0',\n",
       " '.',\n",
       " '9984',\n",
       " 'name',\n",
       " '\\t',\n",
       " 'N',\n",
       " '\\t',\n",
       " '0',\n",
       " '.',\n",
       " '9996',\n",
       " 'is',\n",
       " '\\t',\n",
       " 'V',\n",
       " '\\t',\n",
       " '0',\n",
       " '.',\n",
       " '9973',\n",
       " 'Abhishek',\n",
       " '\\t',\n",
       " '',\n",
       " '^',\n",
       " '',\n",
       " '\\t',\n",
       " '0',\n",
       " '.',\n",
       " '9628',\n",
       " '',\n",
       " '.',\n",
       " '',\n",
       " '\\t',\n",
       " '',\n",
       " ',',\n",
       " '',\n",
       " '\\t',\n",
       " '0',\n",
       " '.',\n",
       " '9975',\n",
       " 'I',\n",
       " '\\t',\n",
       " 'O',\n",
       " '\\t',\n",
       " '0',\n",
       " '.',\n",
       " '9980',\n",
       " 'have',\n",
       " '\\t',\n",
       " 'V',\n",
       " '\\t',\n",
       " '0',\n",
       " '.',\n",
       " '9999',\n",
       " 'no',\n",
       " '\\t',\n",
       " 'D',\n",
       " '\\t',\n",
       " '0',\n",
       " '.',\n",
       " '9911',\n",
       " 'clue',\n",
       " '\\t',\n",
       " 'N',\n",
       " '\\t',\n",
       " '0',\n",
       " '.',\n",
       " '9998',\n",
       " '',\n",
       " '.',\n",
       " '',\n",
       " '\\t',\n",
       " '',\n",
       " ',',\n",
       " '',\n",
       " '\\t',\n",
       " '0',\n",
       " '.',\n",
       " '9985',\n",
       " 'Learning',\n",
       " '\\t',\n",
       " 'V',\n",
       " '\\t',\n",
       " '0',\n",
       " '.',\n",
       " '9957',\n",
       " 'the',\n",
       " '\\t',\n",
       " 'D',\n",
       " '\\t',\n",
       " '0',\n",
       " '.',\n",
       " '9960',\n",
       " 'back',\n",
       " '-',\n",
       " 'portion',\n",
       " '\\t',\n",
       " 'N',\n",
       " '\\t',\n",
       " '0',\n",
       " '.',\n",
       " '8394',\n",
       " 'that',\n",
       " '\\t',\n",
       " 'P',\n",
       " '\\t',\n",
       " '0',\n",
       " '.',\n",
       " '9530',\n",
       " 'I',\n",
       " '\\t',\n",
       " 'O',\n",
       " '\\t',\n",
       " '0',\n",
       " '.',\n",
       " '9989',\n",
       " 'never',\n",
       " '\\t',\n",
       " 'R',\n",
       " '\\t',\n",
       " '0',\n",
       " '.',\n",
       " '9922',\n",
       " 'cared',\n",
       " '\\t',\n",
       " 'V',\n",
       " '\\t',\n",
       " '0',\n",
       " '.',\n",
       " '9976',\n",
       " 'for',\n",
       " '\\t',\n",
       " 'P',\n",
       " '\\t',\n",
       " '0',\n",
       " '.',\n",
       " '9806',\n",
       " '',\n",
       " '.',\n",
       " '',\n",
       " '\\t',\n",
       " '',\n",
       " ',',\n",
       " '',\n",
       " '\\t',\n",
       " '0',\n",
       " '.',\n",
       " '9916',\n",
       " 'Obama',\n",
       " \"'\",\n",
       " 's',\n",
       " '\\t',\n",
       " 'Z',\n",
       " '\\t',\n",
       " '0',\n",
       " '.',\n",
       " '8890',\n",
       " 'nephew',\n",
       " '\\t',\n",
       " 'N',\n",
       " '\\t',\n",
       " '0',\n",
       " '.',\n",
       " '9582',\n",
       " '',\n",
       " '.',\n",
       " '',\n",
       " '\\t',\n",
       " '',\n",
       " ',',\n",
       " '',\n",
       " '\\t',\n",
       " '0',\n",
       " '.',\n",
       " '9976',\n",
       " '',\n",
       " '@',\n",
       " 'random',\n",
       " '\\t',\n",
       " '',\n",
       " '@',\n",
       " '',\n",
       " '\\t',\n",
       " '0',\n",
       " '.',\n",
       " '9960',\n",
       " '',\n",
       " 'Tokenized',\n",
       " ' ',\n",
       " 'and',\n",
       " ' ',\n",
       " 'tagged',\n",
       " ' ',\n",
       " '1',\n",
       " ' ',\n",
       " 'tweets',\n",
       " ' ',\n",
       " '',\n",
       " '(',\n",
       " '23',\n",
       " ' ',\n",
       " 'tokens',\n",
       " ')',\n",
       " '',\n",
       " ' ',\n",
       " 'in',\n",
       " ' ',\n",
       " '0',\n",
       " '.',\n",
       " '7',\n",
       " ' ',\n",
       " 'seconds',\n",
       " ':',\n",
       " '',\n",
       " ' ',\n",
       " '1',\n",
       " '.',\n",
       " '5',\n",
       " ' ',\n",
       " 'tweets',\n",
       " '/',\n",
       " 'sec',\n",
       " ',',\n",
       " '',\n",
       " ' ',\n",
       " '34',\n",
       " '.',\n",
       " '5',\n",
       " ' ',\n",
       " 'tokens',\n",
       " '/',\n",
       " 'sec']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#re.split(r'([^\\w<>])', teststring)\n",
    "list(itertools.chain(*[re.split(r'([^\\w<>])', x) for x in test1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['My', 'D', '0.9984'],\n",
       " ['name', 'N', '0.9996'],\n",
       " ['is', 'V', '0.9973'],\n",
       " ['Abhishek', '^', '0.9628'],\n",
       " ['.', ',', '0.9975'],\n",
       " ['I', 'O', '0.9980'],\n",
       " ['have', 'V', '0.9999'],\n",
       " ['no', 'D', '0.9911'],\n",
       " ['clue', 'N', '0.9998'],\n",
       " ['.', ',', '0.9985'],\n",
       " ['Learning', 'V', '0.9957'],\n",
       " ['the', 'D', '0.9960'],\n",
       " ['back-portion', 'N', '0.8394'],\n",
       " ['that', 'P', '0.9530'],\n",
       " ['I', 'O', '0.9989'],\n",
       " ['never', 'R', '0.9922'],\n",
       " ['cared', 'V', '0.9976'],\n",
       " ['for', 'P', '0.9806'],\n",
       " ['.', ',', '0.9916'],\n",
       " [\"Obama's\", 'Z', '0.8890'],\n",
       " ['nephew', 'N', '0.9582'],\n",
       " ['.', ',', '0.9976'],\n",
       " ['@random', '@', '0.9960']]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1_list = list([re.split(r'([\\t])',x) for x in test1])\n",
    "test1_list = [[ item for item in word if item != '\\t' ] for word in test1_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My</td>\n",
       "      <td>D</td>\n",
       "      <td>0.9984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>name</td>\n",
       "      <td>N</td>\n",
       "      <td>0.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is</td>\n",
       "      <td>V</td>\n",
       "      <td>0.9973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abhishek</td>\n",
       "      <td>^</td>\n",
       "      <td>0.9628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.</td>\n",
       "      <td>,</td>\n",
       "      <td>0.9975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I</td>\n",
       "      <td>O</td>\n",
       "      <td>0.9980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>have</td>\n",
       "      <td>V</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>no</td>\n",
       "      <td>D</td>\n",
       "      <td>0.9911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>clue</td>\n",
       "      <td>N</td>\n",
       "      <td>0.9998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>.</td>\n",
       "      <td>,</td>\n",
       "      <td>0.9985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Learning</td>\n",
       "      <td>V</td>\n",
       "      <td>0.9957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>the</td>\n",
       "      <td>D</td>\n",
       "      <td>0.9960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>back-portion</td>\n",
       "      <td>N</td>\n",
       "      <td>0.8394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>that</td>\n",
       "      <td>P</td>\n",
       "      <td>0.9530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I</td>\n",
       "      <td>O</td>\n",
       "      <td>0.9989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>never</td>\n",
       "      <td>R</td>\n",
       "      <td>0.9922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cared</td>\n",
       "      <td>V</td>\n",
       "      <td>0.9976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>for</td>\n",
       "      <td>P</td>\n",
       "      <td>0.9806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>.</td>\n",
       "      <td>,</td>\n",
       "      <td>0.9916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Obama's</td>\n",
       "      <td>Z</td>\n",
       "      <td>0.8890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>nephew</td>\n",
       "      <td>N</td>\n",
       "      <td>0.9582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>.</td>\n",
       "      <td>,</td>\n",
       "      <td>0.9976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>@random</td>\n",
       "      <td>@</td>\n",
       "      <td>0.9960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word tag confidence\n",
       "0             My   D     0.9984\n",
       "1           name   N     0.9996\n",
       "2             is   V     0.9973\n",
       "3       Abhishek   ^     0.9628\n",
       "4              .   ,     0.9975\n",
       "5              I   O     0.9980\n",
       "6           have   V     0.9999\n",
       "7             no   D     0.9911\n",
       "8           clue   N     0.9998\n",
       "9              .   ,     0.9985\n",
       "10      Learning   V     0.9957\n",
       "11           the   D     0.9960\n",
       "12  back-portion   N     0.8394\n",
       "13          that   P     0.9530\n",
       "14             I   O     0.9989\n",
       "15         never   R     0.9922\n",
       "16         cared   V     0.9976\n",
       "17           for   P     0.9806\n",
       "18             .   ,     0.9916\n",
       "19       Obama's   Z     0.8890\n",
       "20        nephew   N     0.9582\n",
       "21             .   ,     0.9976\n",
       "22       @random   @     0.9960"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdtest2 = pd.DataFrame(test1_list[1:-2], columns = ['word','tag','confidence'] )\n",
    "pdtest2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
